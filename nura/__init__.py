import numpy as np
import nura.autograd.graph as graph
import nura.autograd.forwardad as forwardad

from .autograd.functional import backward, grad
from .autograd.mode import Autograd, usegrad, nograd, setgrad, forwardmode
from .types import char, byte, short, int, long, half, float, double, bool, dtypeof, inf
from .tensors import tensor

from .functional import (
    add,
    iadd,
    sub,
    isub,
    mul,
    imul,
    div,
    idiv,
    floordiv,
    ifloordiv,
    modulo,
    imodulo,
    dot,
    matmul,
    imatmul,
    pow,
    ipow,
    square,
    sqrt,
    exp,
    log,
    sin,
    cos,
    sum,
    max,
    min,
    transpose,
    permute,
    squeeze,
    unsqueeze,
    reshape,
    abs,
    pos,
    neg,
    clone,
    select,
)

from .utils import (
    empty,
    emptylike,
    zeros,
    zeroslike,
    ones,
    oneslike,
    randn,
    randnlike,
    rand,
    randlike,
    randint,
    randintlike,
    identity,
    tri,
    triu,
    tril,
    full,
    eye,
    where,
    indexwhere,
    nonzero,
    argmax,
    argmin,
    hashtensor,
    equal,
    less,
    lesseq,
    greater,
    greatereq,
    noteq,
    tensorany,
    tensorall,
    tensorand,
    tensoror,
    tensorxor,
    tensornot,
    tensorinvert,
    typesmatch,
    item,
    to,
    tocontiguous,
    todim,
    onehot,
    iscontiguous,
    typename,
    totensor,
)


np.set_printoptions(precision=4)
